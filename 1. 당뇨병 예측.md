# 1. 데이터셋 살펴보기 

| feature                  |                |
| ------------------------ | -------------- |
| Pregnancies              | 임신횟수           |
| Glucose                  | 포도당 농도         |
| BloodPressure            | 혈압             |
| SkinThickness            | 피부 두께          |
| Insulin                  | 인슐린            |
| BMI                      | 체질량지수          |
| DiabetesPedigreeFunction | 당뇨병 혈통 기능      |
| Age                      | 나이             |
| Outcome                  | 당뇨병 여부(Target) |

: 21세 이상 여성으로 구성된 '피마 인디언 데이터'를 통해 당뇨병 여부를 예측

# 2. 데이터 확인하기 

## 1. train.info() 
: 데이터의 컬럼명, 결측값 수, 데이터 타입을 출력 
![](Pasted%20image%2020250310164138.png)

## 2. train.describe() 
: 기술통계량을 출력함. 

![](Pasted%20image%2020250310164300.png)

# 3. train[ ].describe()
![](Pasted%20image%2020250310164402.png)

# 4. 무작위 데이터 추출 
train.sample() 
train.sample(5)

# 5. 인덱스 추출 
```python 
list(trian.values)[:10]
```
![](Pasted%20image%2020250310164953.png)

# 6. Age feature의 값 잘라내기 
```python 
train_age = train['Age'].values
```

**array([33, 36, 38, 26, 21, 26, 23, 42, 21, 33])**

# 7. feature의 데이터 타입 확인 
```python 
train['Age'].dtypes
```

**dtype('int64')**

# 8. feature의 데이터 타입 변환 
```python 
train['Age'].astype(float)
```

타입 변환 후, 데이터 타입 확인

```python 
bmi_int = train['BMI'].astype(int).dtypes
bmi_int
```

**dtype('int64')**

# 8. 행 단위로 데이터 불러오기 
```python
train.iloc[[1]] # 행 1개 불러오기 
trian.iloc[1:4] # 1번 인덱스부터 3번 인덱스까지 데이터를 읽어오기
print('Glucose 피처의 값이 170 이상인 수 : ',len(train[train['Glucose'] >= 170])) 
# [train['Glucose'] >= 170] => [True, False, False, False] 이런 boolean series로 저장됨. 
# 그러면 train[True, False, False, False]이런 꼴이 되는 거임. 
```
![](Pasted%20image%2020250310171018.png)
: loc 메서드를 활용하여 데이터 필터링 및 값 변경 
```python 
train.loc[train['Glucose'] >= 170 , 'Glucose'] = 169
```

# 9. feature의 클래스 별 빈도 확인 
```python 
train['Outcome'].value_counts() 
```
![](Pasted%20image%2020250310171219.png)

: feature의 클래스 별 비율 확인 
	: value_counts() 메서드의 normalize인자의 값을 True로 설정하여 각 클래스 별 등장 비율을 확인 
```python 
train['Outcome'].value_counts(normalize = True)
```
![](Pasted%20image%2020250310171349.png)

# 10. pd.cut() 함수를 이용하여 column 값을 3개 구간으로 분류하기 
```python 
train['bloodpressure_cut'] = pd.cut(
	train['BloodPressure'],
	bins = [0, 40, 80, 120], 
	labels = ['A', 'B', 'C'], 
	right = False
)
# BloodPressure(혈압) 값을 특정 구간으로 나누고, 각 구간에 A/B/C라는 라벨을 할당하는 역할 
print(train['bloodpressure_cut'].value_counts(sort = False))


# 결국 위 코드랑 아래 코드랑 같은 역할을 한다. 
print('혈압이 40 미만인 값 : ', 
    len(train[train['BloodPressure'] < 40]))
print('혈압이 40이상 80미만인 값 : ',
    len(train[(train['BloodPressure'] >= 40) & (train['BloodPressure'] < 80)]))
print('혈압이 80이상인 값 : ',
    len(train[(train['BloodPressure'] >= 80) & (train['BloodPressure'] < 120)]))
```

# 11. pd.qcut() 
: 데이터를 4개의 구간으로 나누기
: 데이터의 분포에 따라 자동으로 같은 개수의 그룹으로 나눔 

```python 
train['bloodpressure_cut'] = pd.qcut(train['BloodPressure'], q = 4, labels = ['A', 'B', 'C', 'D'])
train['bloodpressure_cut'].value_counts(sort = False)
```

# 12. StandardScalar를 이용한 train 데이터 표준화 
```python 
from sklearn.preprocessing import StandardScaler

scaler = StandardScalar() 
scaler.fit(train.loc[:, 'Pregnancies': 'Age'])
```

```python 
scaled_train = scaler.transform(train.loc[:,'Pregnancies':'Age'])
scaled_test = scaler.transform(test.loc[:,'Pregnancies':'Age'])

sequential_features = scaler.feature_names_in_
# scaler.features_names_in_ : StandardScaler가 fit()을 수행할 때 사용했던 입력(feature) 이름들을 저장하는 속성

for index, feature in enumerate(sequential_features):
    train[feature] = scaled_train[:,index]
    test[feature] = scaled_test[:,index]
    
train.head()

print(sequential_features) 
```

# 13. LabelEncoder를 활용한 범주형 데이터 인코딩 
```python 
from sklearn.preprocessing import LabelEncoder

le = LableEncoder() 

le = le.fit(x_train['binning_glucose']) # x_train의 평균과 표준편차를 학습(계산)
x_train['binning_glucose'] = le.transform(x_train['binning_glucose'])
# fit()에서 학습된 평균과 표준편차를 사용하여 x_train을 반환
```

```python 
import numpy as np

# Categorical 타입을 문자열로 변환
x_test['binning_glucose'] = x_test['binning_glucose'].astype('category')

# 'nan' 문자열을 'unknown'으로 대체
x_test['binning_glucose'] = x_test['binning_glucose'].replace('nan', 'unknown')

#'unknown' 라벨이 LabelEncoder에 없으면 추가
if 'unknown' not in le.classes_:
    le.classes_ = np.append(le.classes_, 'unknown')

x_test['binning_glucose'] = le.transform(x_test['binning_glucose'])
```

# 14. logistic regression 모델 정의
```python 
from sklearn.linear_model import LogisticRegression 

model = LogisticRegression() 
```

```python
model.fit(x_train, y_train)
predict = model.predict(x_test)
```

```python 
submission['Outcome'] = predict 

submission.to_csb('submission.csv', index = False, quoting = 2, encoding="utf-8-sig", na_rep=0, float_format='%.6f')
```


이렇게하면 점수 0.7844827586206896 나옴 
2025-03-11
#이진분류 #분류 
  
------

# 1. 이진 분류 문제 초기 데이터 탐색

데이터 불러오기
데이터 확인 

```python 
import pandas as pd

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
submission = pd.read_csv('sample_submission.csv')

display(train.head())
display(test.head())
display(submission.head())

```

데이터 비율이나 그런거는 입문이랑 내용 같음 

# 2. Target 변수 class 별 빈도수 및 비율 시각화 

```python 
import matplotlib.pyplot as plt 
import seaborn as sns

# target ratio 계산 
target_ratio = round(train['Outcome'].value_counts(normalize= True)*100, 2)
''' 
value_counts() : Outcome 열의 각 고유 값이 몇 번 등장하는지 세는 함수. 
normalize = True : 값의 개수가 비율로 변환됨. 
round(...,2) : 결과를 소수점 둘째 자리까지 반올림하겠다. 
'''
plt.figure(figsize = (6,4)) # matplotlib에서 그래프의 크기를 설정하는 코드
ax = sns.countplot(x='Outcome', data= train) # outcome 컬럼의 빈도수를 막대 그래프로 그리는 코드 
'''
sns.countplot() : 데이터프레임에서 특정 컬럼의 값 개수를 세어 막대 그래프로 시각화하는 함수 
x = 'Outcome' : 가로추겡 Outcome 컬럼을 사용하겠다. 
data = train : train이라는 데이터 프레임에서 Outcome 컬럼을 가지고 오겠다. 
'''

# 막대 위에 퍼센트 값 표시 
for i, patch in enumerate(ax.patches): # ax.patches : matplotlib에서 생성된 막대 객체들의 리스트를 반환
	height = patch.get_height() # 높이 가지고 오기 
	ax.text(patch.get_x() + patch.get_width()/2., 
	# get_x() : 막대의 왼쪽 끝 x 좌표를 가지고 옴. 
	# get_width()/2 : 막대 너비 절반을 더해 막대의 중심을 찾음
	height, 
	'{:.2f}%'.format(target_ratio[i]),
	ha = "center" )
	# target_ratio[i] : 해당 막대의 비율 값(예: 35.67)
	# {:.2f}% : 소수점 둘째 자리까지 표시하고 퍼센트 기호 추가 


```

# 3. feature  변수의 분포 확인 
```python 
feature = train.column[1:-1]

plt.figure(figsize = (10, 6)) # 10인치, 6인치 

for idx, feature in enumerate(features): 
	ax1 = plt.subplot(3,3,idx+1)
	# plt.subplot() : 3x3(총 9개) 서브 플롯(작은 그래프)을 생성
	plt.title(feature) # 현재 플롯(서브플롯)의 제목을 feature(현재 칼럼명)으로 설정
	plt.tight_layout() # 그래프 간의 간격을 자동으로 조정하여 레이아웃이 겹치지 않도록 정렬 
	sns.histplot(x=feature, data = train, kde = True)# 히스토그램을 그리는 seaborn 함수 
	# x=feature : x축에 현재 반복 중인 컬럼의 데이터를 사용
	# data=train : train 데이터 프레임에서 데이터를 가져옴 
	# kde= True : 커널 밀도 추정 곡선을 함께 그림(곡선으로 표현 됨)

plt.show() 
```

![](Pasted%20image%2020250312151623.png)

# 4. feature들의 target class 별 빈도수 시각화 
```python 
selected_feature = 'BMI'  # 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'

plt.figure(figsize=(8,4))

# 사분위 수 계산
# np.percentile() : 데이터에서 특정 분위수 값을 계산하는 함수
q1 = np.percentile(train[selected_feature], 25) # 25% 분위수(Q1)
q2 = np.percentile(train[selected_feature], 50) # 50% 분위수(Q2)
q3 = np.percentile(train[selected_feature], 75) # 75% 분위수(Q3)
q4 = np.percentile(train[selected_feature], 100) # 100% 분위수(Q4)

# Q1 (25%): 32.5 : 전체 데이터 중 하위 25%에 해당하는 값 
# Q2 (50%, 중앙값): 55.0 # 데이터의 중간 값(중앙값)
# Q3 (75%): 77.5  : 전체 데이터 중 하위 75%에 해당하는 값 

q_lst = [ 0, q1, q2, q3, q4]

# target class 1의 갯수 대비 target class 0의 갯수의 비율 구하기
num_class0 = len(train [ train['Outcome'] == 0 ])
num_class1 = len(train [ train['Outcome'] == 1 ])

ratio_class1_class0 = num_class0 / num_class1

# 히스토그램 그리기
plt.figure(figsize=(8, 4))
h0_ax1 = sns.histplot(data=train[train['Outcome'] == 0], x=selected_feature, bins = q_lst, color = 'g',  alpha=0.3,  label='Outcome = 0')
h1_ax1 = sns.histplot(data=train[train['Outcome'] == 1], x=selected_feature, bins = q_lst, color = 'r',  alpha=0.3,  label='Outcome = 1')

# target 변수의 class가 1일 때의 각 bin의 높이(개수)와 경계값을 얻어옵니다
h1_heights, h1_edges = np.histogram(train[train['Outcome'] == 1][selected_feature], bins=q_lst)
## target 변수가 1인 데이터마늘 사용하여 히스토그램을 그리고, 각 구간(bin)의 개수(높이)와 경계값을 저장하는 역할
## bins = q_lst : 분위수(사분위수, quantile) 기반 구간을 사용하여 히스토그램을 생성. 

# target class 1의 갯수 대비 target class 0의 갯수의 비율과 일치하는 각 구간의 수평선을 그린다
for i in range(len(h1_heights)):
    plt.hlines(y=h1_heights[i] * ratio_class1_class0 , xmin=h1_edges[i], xmax=h1_edges[i+1], linestyles='solid', colors='red', alpha=0.5)

plt.gca().set_title(f"{selected_feature} (quantile based)")

plt.tight_layout()
plt.show()

```

# 5. feature들의 분포 및 이상치 탐색 

```python 
features = train.columns[1:-1]

plt.figure(figsize=(10,6))

for idx, feature in enumerate(feature): 
	ax1 = plt.subplot(3,3, idx+1)
	plt.title(feature)
	plt.tight_layout() 
	sns.boxplot(x='Outcome', y=feature, data = train)

plt.show() 
```

![](Pasted%20image%2020250312160215.png)

+) boxplot 해석하는 방법 
(1) 중앙값(Median, Q2, 50%)
	- 박스의 내부의 가로선이 데이터의 중앙값을 나타냄
	- 데이터가 정규분포에 가까울수록 박스의 가운데에 위치함. 
(2) 사분위 범위(Interquartile Range, IQR)
	- 박스의 아래쪽(하단) 경계 -> 1사분위수(Q1, 25%)
	- 박스의 위쪽(상단) 경계 -> 3사분위수(Q3, 75%) 
	- IQR = Q3 - Q1(데이터의 중간 50%가 포함된 범위)
(3) 수염(Whiskers)
	- Q1-1.5 x IQR (최소 경계)
	- Q3+1.5 x IQR (최대 경계)
	- 위 범위 내에 있는 데이터를 정상 범위로 간주하고 , 그 바깥은 이상치로 처리 
(4) 이상치(Outfilers)
	- 수염 밖의 점들
# 6. feature 변수쌍과 target과의 연관관계 시각화 
```python 
plt.figure(figsize=(3,2))

#features_to_analyze = train.columns[1:]
features_to_analyze = ['Insulin', 'SkinThickness', 'Glucose', 'BMI', 'Outcome']
sns.pairplot(train[features_to_analyze], hue='Outcome')

plt.show()
```
![](Pasted%20image%2020250312160528.png)

+) pairplot()
: 데이터프레임의 모든 숫자형 변수 간의 관계를 산점도와 히스토그램으로 시각화하는 함수 
: 변수 간 관계를 파악할 수 있으며, 패턴이나 상관관계를 찾는 데 유용함. 

해석하는 방법 
(1) 변수 간 관계(상관관계)
- 양의 상관관계 : 오른쪽 위로 향하는 패턴(예: 키와 몸무게)
- 음의 상관관계 : 왼쪽 위로 향하는 패턴(예: 나이와 운동량)
- 무관계 : 점들이 랜덤하게 퍼져 있음 -> 상관관계가 약함

(2) 데이터의 분포 
- 대각선에는 각 변수의 히스토그램 or KDE(커널 밀도 추정)곡선이 표시됨 
- 데이터가 어느 구간에 많이 몰렸는지  확인 가능 
(3) 이상치(Outliters) 확인 
- 특정 변수에서 다른 데이터들과 동떨어진 점들이 있다면, 이상치일 가능성이 높음

# 7. 수치형 feature와 이진 범주형 target 간의 상관관계 
- 점 이연 상관관계(Point Biserial Correlation)
  : 연속형 변수와 이진형 변수 사이의 상관관계를 측정하는 방법, 이를 통해 각 feature와 target 변수 사이의 관계를 수치로 이해할 수 있다. 
```python 
from scipy.stats import pointbiserialr

correlation_org_lst, correlation_dealout_lst = [], []
p_value_org_lst, p_value_dealout_lst = [], []

feature_lst = train.columns[1:-1].to_list()

# 점 이연 상관계수 계산 및 출력
for feature in feature_lst:
    correlation_org, p_value_org = pointbiserialr(train[feature], train['Outcome'])
    '''
    pointbiserialr(train[feature], train['Outcome']) 
    : 점이연 상관계수를 계산하는 함수 
    : feature가 연속형(수치형) 변수, Outcome이 이진형(범주형) 변수일 때 사용 
    : correlation_org : 해당 feature와 outcome 간의 상관계수 
    : p_value_org : 해당 상관관계의 유의확률(p-value, 상관관계의 통계적 유의성 판단)
    '''
    correlation_org_lst.append(correlation_org)
    p_value_org_lst.append(p_value_org)


# 데이터프레임 생성
correlation_dict = {'Feature': feature_lst,
                    'correlation_org': correlation_org_lst,
                    'p_value_org' : p_value_org_lst  }

correlation_df = pd.DataFrame(correlation_dict)

display(correlation_df)
```

- 시각화 
```python 
import matplotlib.pyplot as plt
import seaborn as sns
# Seaborn barplot

plt.figure(figsize=(16, 8))

plt.subplot(2,2,1)
sns.barplot(x='Feature', y='correlation_org', data=correlation_df)
plt.gca().set_title("Point Biserial Correlation [original train]")
plt.gca().set_xticklabels(feature_lst, rotation=30)

plt.subplot(2,2,2)
sns.barplot(x='Feature', y='p_value_org', data=correlation_df)
plt.gca().set_xticklabels(feature_lst, rotation=30)
plt.gca().set_title("p_value [original train]")

plt.show()
```

# 8. feature 간 상관 관계 
: 히트맵 사용 
```python 
import matplotlib.pyplot as plt
import seaborn as sns

features = train.columns[1:-1]
# 이번 셀에서 출력할 이미지 크기를 지정합니다.
plt.figure(figsize = (8,4))

# annot을 False로 설정하면 각 셀의 수치가 표기되지 않습니다.
sns.heatmap(train[features].corr(), cmap = "coolwarm", annot = True)
plt.show()
```
![](Pasted%20image%2020250312170240.png)

# 9. 다중 공선성과 VIF를 이해하고 측정하기 
#VIF (Variance Inflation Factor)
: 피처 간의 다중 공선성을 측정하는 지표, 특정 피처가 다른 피처들로 얼마나 잘 설명될 수 있는지를 나타냄. 
```python 
# Import required libraries
from statsmodels.stats.outliers_influence import variance_inflation_factor

features_org = train.columns[1:-1]
train_x = train[features_org]

vif = pd.DataFrame()
vif["features"] = train_x.columns

# 빈 리스트를 생성합니다.
VIF_list = []

# 각 피처에 대해 반복합니다.
for i in range(len(train_x.columns)):

    # variance_inflation_factor 함수를 사용하여 해당 피처의 VIF 값을 계산합니다.
    VIF_value = variance_inflation_factor(train_x.values, i)

    # 계산된 VIF 값을 리스트에 추가합니다.
    VIF_list.append(VIF_value)

# VIF 값 리스트를 DataFrame에 추가합니다.
vif["VIF"] = VIF_list

display(vif)

# Set the figure size
plt.figure(figsize=(10, 4))

# Create a bar plot of VIF values
sns.barplot(x="VIF", y="features", data=vif.sort_values("VIF", ascending=False))

# Show the plot
plt.show() 
```
![](Pasted%20image%2020250312170437.png)

# 10. RandomForest에 의한 feature 중요도 확인 
```python 
from sklearn.ensemble import RandomForestClassifier

features = train.columns[:-1]
train_x = train.iloc[:, 1:-1]
train_y = train.iloc[:,-1]

RF_model = RandomForestClassifier(random_state = 42)
RF_model.fit(train_x,train_y)
importances = RF_model.feature_importances_ 
feature_names = RF_model.feature_names_in_ 

plt.figure(figsize=(12,4))
sns.barplot(x=feature_names, y= importances)
plt.show()
```
![](Pasted%20image%2020250312171333.png)

# 11. Logistic Regression에 이한 feature 중요도 확인 

- 데이터 표준화 : StandardScalar를 사용하여 feature들을 표준화한다. 이렇게하면 feature가 동일한 스케일을 갖게 되어, 모델의 훈련 성능이 향상 된다. 
- 표준화란? 평균을 0, 표준편차를 1로 조정하는 과정
```python 
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

features = list(train.columns[1:-1])
train_x = train[features]
train_y = train['Outcome']

scaler = StandardScaler()
train_scaled_x = train_x.copy()
train_scaled_x[features] = scaler.fit_transform(train_x)

LR_model = LogisticRegression(random_state = 42, max_iter=2000)
LR_model.fit(train_scaled_x,train_y)
importances = list(np.abs(LR_model.coef_[0]))
feature_names = features

display(importances)
display(feature_names)
plt.figure(figsize=(12,4))
sns.barplot(x=feature_names, y= importances)

plt.show()
```
![](Pasted%20image%2020250312172154.png)

# 12. 기본 교차 검증 성능 
: 랜더 포레스트 분류기를 사용하여 교차 검증(cross-validation)을 수행하고, 다양한 평가 지표를 기반으로 모델의 성능을 평가한다. 
+) 교차 검증 : 훈련 데이터와 테스트 데이터를 나누는 방법. 
+) K-Fold를 사용한 교차 검증 : 데이터를 여러 개의 폴드(fold)로 나누고, 각 폴드가 한번씩 테스트셋이 되도록 반복 -> 모든 데이터를 학습에 활용 가능
+) 4-Fold 교차 검증 -> 훈련 데이터를 4개 폴드로 나눈다. ![](Pasted%20image%2020250312175130.png)
: StratifiedKFold를 사용하여 훈련 데이터를 4개의 폴드로 나누고, 각 폴드에서의 정확도, 정밀도, 재현율, F1 점수를 계산한다. 
```python 
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold

features_org = train[:-1]

train_x = train.iloc[:, 1:-1]
train_y = train['Outcome']

kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
'''
StratifiedKFold 
: 타겟 변수에서 각 클래스(0, 1)의 비율을 유지하면서 데이터를 4개 폴드(fold)로 나눔(원본 데이터와 동일하게 유지됨) 
'''

# 계층적 K-Fold 교차 검증 사용
display("#######  기본 교차 검증 성능  #########")

RF_model = RandomForestClassifier(random_state = 42)
cv_result = cross_validate(RF_model, train_x, train_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
'''
cross_validate
: 교차 검증을 수행하여 머신러닝 모델의 성능을 평가하는 함수. 
: K-Fold, StratifiedKFold와 함께 사용되어, 데이터를 여러 개의 폴드로 나누고, 모델을 반복적으로 학습 및 평가하여 성능을 측정한다. 
:train_test_split()와 달리 데이터를 여러번 학습하고 평가하여 평균 성능을 측정한다. 
: 단순히 정확도(acc)만 계산하는 cross_val_score()와 달리, 정밀도(precision), 재현율(recall), F1-score 등 다양한 평가 지표를 한번에 반환할 수 있다. 
: 훈련시간(fit_time), 테스트 시간(score_time) 정보 제공


'''
df_cv_result = pd.DataFrame(cv_result, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(df_cv_result)
display(df_cv_result.describe().loc['mean',:].round(4).T)
```
2025-03-11
#이진분류 #분류 
  
------

# 1. 이진 분류 문제 초기 데이터 탐색

데이터 불러오기
데이터 확인 

```python 
import pandas as pd

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
submission = pd.read_csv('sample_submission.csv')

display(train.head())
display(test.head())
display(submission.head())

```

데이터 비율이나 그런거는 입문이랑 내용 같음 

# 2. Target 변수 class 별 빈도수 및 비율 시각화 

```python 
import matplotlib.pyplot as plt 
import seaborn as sns

# target ratio 계산 
target_ratio = round(train['Outcome'].value_counts(normalize= True)*100, 2)
''' 
value_counts() : Outcome 열의 각 고유 값이 몇 번 등장하는지 세는 함수. 
normalize = True : 값의 개수가 비율로 변환됨. 
round(...,2) : 결과를 소수점 둘째 자리까지 반올림하겠다. 
'''
plt.figure(figsize = (6,4)) # matplotlib에서 그래프의 크기를 설정하는 코드
ax = sns.countplot(x='Outcome', data= train) # outcome 컬럼의 빈도수를 막대 그래프로 그리는 코드 
'''
sns.countplot() : 데이터프레임에서 특정 컬럼의 값 개수를 세어 막대 그래프로 시각화하는 함수 
x = 'Outcome' : 가로추겡 Outcome 컬럼을 사용하겠다. 
data = train : train이라는 데이터 프레임에서 Outcome 컬럼을 가지고 오겠다. 
'''

# 막대 위에 퍼센트 값 표시 
for i, patch in enumerate(ax.patches): # ax.patches : matplotlib에서 생성된 막대 객체들의 리스트를 반환
	height = patch.get_height() # 높이 가지고 오기 
	ax.text(patch.get_x() + patch.get_width()/2., 
	# get_x() : 막대의 왼쪽 끝 x 좌표를 가지고 옴. 
	# get_width()/2 : 막대 너비 절반을 더해 막대의 중심을 찾음
	height, 
	'{:.2f}%'.format(target_ratio[i]),
	ha = "center" )
	# target_ratio[i] : 해당 막대의 비율 값(예: 35.67)
	# {:.2f}% : 소수점 둘째 자리까지 표시하고 퍼센트 기호 추가 


```

# 3. feature  변수의 분포 확인 
```python 
feature = train.column[1:-1]

plt.figure(figsize = (10, 6)) # 10인치, 6인치 

for idx, feature in enumerate(features): 
	ax1 = plt.subplot(3,3,idx+1)
	# plt.subplot() : 3x3(총 9개) 서브 플롯(작은 그래프)을 생성
	plt.title(feature) # 현재 플롯(서브플롯)의 제목을 feature(현재 칼럼명)으로 설정
	plt.tight_layout() # 그래프 간의 간격을 자동으로 조정하여 레이아웃이 겹치지 않도록 정렬 
	sns.histplot(x=feature, data = train, kde = True)# 히스토그램을 그리는 seaborn 함수 
	# x=feature : x축에 현재 반복 중인 컬럼의 데이터를 사용
	# data=train : train 데이터 프레임에서 데이터를 가져옴 
	# kde= True : 커널 밀도 추정 곡선을 함께 그림(곡선으로 표현 됨)

plt.show() 
```

![](Pasted%20image%2020250312151623.png)

# 4. feature들의 target class 별 빈도수 시각화 
```python 
selected_feature = 'BMI'  # 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'

plt.figure(figsize=(8,4))

# 사분위 수 계산
# np.percentile() : 데이터에서 특정 분위수 값을 계산하는 함수
q1 = np.percentile(train[selected_feature], 25) # 25% 분위수(Q1)
q2 = np.percentile(train[selected_feature], 50) # 50% 분위수(Q2)
q3 = np.percentile(train[selected_feature], 75) # 75% 분위수(Q3)
q4 = np.percentile(train[selected_feature], 100) # 100% 분위수(Q4)

# Q1 (25%): 32.5 : 전체 데이터 중 하위 25%에 해당하는 값 
# Q2 (50%, 중앙값): 55.0 # 데이터의 중간 값(중앙값)
# Q3 (75%): 77.5  : 전체 데이터 중 하위 75%에 해당하는 값 

q_lst = [ 0, q1, q2, q3, q4]

# target class 1의 갯수 대비 target class 0의 갯수의 비율 구하기
num_class0 = len(train [ train['Outcome'] == 0 ])
num_class1 = len(train [ train['Outcome'] == 1 ])

ratio_class1_class0 = num_class0 / num_class1

# 히스토그램 그리기
plt.figure(figsize=(8, 4))
h0_ax1 = sns.histplot(data=train[train['Outcome'] == 0], x=selected_feature, bins = q_lst, color = 'g',  alpha=0.3,  label='Outcome = 0')
h1_ax1 = sns.histplot(data=train[train['Outcome'] == 1], x=selected_feature, bins = q_lst, color = 'r',  alpha=0.3,  label='Outcome = 1')

# target 변수의 class가 1일 때의 각 bin의 높이(개수)와 경계값을 얻어옵니다
h1_heights, h1_edges = np.histogram(train[train['Outcome'] == 1][selected_feature], bins=q_lst)
## target 변수가 1인 데이터마늘 사용하여 히스토그램을 그리고, 각 구간(bin)의 개수(높이)와 경계값을 저장하는 역할
## bins = q_lst : 분위수(사분위수, quantile) 기반 구간을 사용하여 히스토그램을 생성. 

# target class 1의 갯수 대비 target class 0의 갯수의 비율과 일치하는 각 구간의 수평선을 그린다
for i in range(len(h1_heights)):
    plt.hlines(y=h1_heights[i] * ratio_class1_class0 , xmin=h1_edges[i], xmax=h1_edges[i+1], linestyles='solid', colors='red', alpha=0.5)

plt.gca().set_title(f"{selected_feature} (quantile based)")

plt.tight_layout()
plt.show()

```

# 5. feature들의 분포 및 이상치 탐색 

```python 
features = train.columns[1:-1]

plt.figure(figsize=(10,6))

for idx, feature in enumerate(feature): 
	ax1 = plt.subplot(3,3, idx+1)
	plt.title(feature)
	plt.tight_layout() 
	sns.boxplot(x='Outcome', y=feature, data = train)

plt.show() 
```

![](Pasted%20image%2020250312160215.png)

+) boxplot 해석하는 방법 
(1) 중앙값(Median, Q2, 50%)
	- 박스의 내부의 가로선이 데이터의 중앙값을 나타냄
	- 데이터가 정규분포에 가까울수록 박스의 가운데에 위치함. 
(2) 사분위 범위(Interquartile Range, IQR)
	- 박스의 아래쪽(하단) 경계 -> 1사분위수(Q1, 25%)
	- 박스의 위쪽(상단) 경계 -> 3사분위수(Q3, 75%) 
	- IQR = Q3 - Q1(데이터의 중간 50%가 포함된 범위)
(3) 수염(Whiskers)
	- Q1-1.5 x IQR (최소 경계)
	- Q3+1.5 x IQR (최대 경계)
	- 위 범위 내에 있는 데이터를 정상 범위로 간주하고 , 그 바깥은 이상치로 처리 
(4) 이상치(Outfilers)
	- 수염 밖의 점들
# 6. feature 변수쌍과 target과의 연관관계 시각화 
```python 
plt.figure(figsize=(3,2))

#features_to_analyze = train.columns[1:]
features_to_analyze = ['Insulin', 'SkinThickness', 'Glucose', 'BMI', 'Outcome']
sns.pairplot(train[features_to_analyze], hue='Outcome')

plt.show()
```
![](Pasted%20image%2020250312160528.png)

+) pairplot()
: 데이터프레임의 모든 숫자형 변수 간의 관계를 산점도와 히스토그램으로 시각화하는 함수 
: 변수 간 관계를 파악할 수 있으며, 패턴이나 상관관계를 찾는 데 유용함. 

해석하는 방법 
(1) 변수 간 관계(상관관계)
- 양의 상관관계 : 오른쪽 위로 향하는 패턴(예: 키와 몸무게)
- 음의 상관관계 : 왼쪽 위로 향하는 패턴(예: 나이와 운동량)
- 무관계 : 점들이 랜덤하게 퍼져 있음 -> 상관관계가 약함

(2) 데이터의 분포 
- 대각선에는 각 변수의 히스토그램 or KDE(커널 밀도 추정)곡선이 표시됨 
- 데이터가 어느 구간에 많이 몰렸는지  확인 가능 
(3) 이상치(Outliters) 확인 
- 특정 변수에서 다른 데이터들과 동떨어진 점들이 있다면, 이상치일 가능성이 높음

# 7. 수치형 feature와 이진 범주형 target 간의 상관관계 
- 점 이연 상관관계(Point Biserial Correlation)
  : 연속형 변수와 이진형 변수 사이의 상관관계를 측정하는 방법, 이를 통해 각 feature와 target 변수 사이의 관계를 수치로 이해할 수 있다. 
```python 
from scipy.stats import pointbiserialr

correlation_org_lst, correlation_dealout_lst = [], []
p_value_org_lst, p_value_dealout_lst = [], []

feature_lst = train.columns[1:-1].to_list()

# 점 이연 상관계수 계산 및 출력
for feature in feature_lst:
    correlation_org, p_value_org = pointbiserialr(train[feature], train['Outcome'])
    '''
    pointbiserialr(train[feature], train['Outcome']) 
    : 점이연 상관계수를 계산하는 함수 
    : feature가 연속형(수치형) 변수, Outcome이 이진형(범주형) 변수일 때 사용 
    : correlation_org : 해당 feature와 outcome 간의 상관계수 
    : p_value_org : 해당 상관관계의 유의확률(p-value, 상관관계의 통계적 유의성 판단)
    '''
    correlation_org_lst.append(correlation_org)
    p_value_org_lst.append(p_value_org)


# 데이터프레임 생성
correlation_dict = {'Feature': feature_lst,
                    'correlation_org': correlation_org_lst,
                    'p_value_org' : p_value_org_lst  }

correlation_df = pd.DataFrame(correlation_dict)

display(correlation_df)
```

- 시각화 
```python 
import matplotlib.pyplot as plt
import seaborn as sns
# Seaborn barplot

plt.figure(figsize=(16, 8))

plt.subplot(2,2,1)
sns.barplot(x='Feature', y='correlation_org', data=correlation_df)
plt.gca().set_title("Point Biserial Correlation [original train]")
plt.gca().set_xticklabels(feature_lst, rotation=30)

plt.subplot(2,2,2)
sns.barplot(x='Feature', y='p_value_org', data=correlation_df)
plt.gca().set_xticklabels(feature_lst, rotation=30)
plt.gca().set_title("p_value [original train]")

plt.show()
```

# 8. feature 간 상관 관계 
: 히트맵 사용 
```python 
import matplotlib.pyplot as plt
import seaborn as sns

features = train.columns[1:-1]
# 이번 셀에서 출력할 이미지 크기를 지정합니다.
plt.figure(figsize = (8,4))

# annot을 False로 설정하면 각 셀의 수치가 표기되지 않습니다.
sns.heatmap(train[features].corr(), cmap = "coolwarm", annot = True)
plt.show()
```
![](Pasted%20image%2020250312170240.png)

# 9. 다중 공선성과 VIF를 이해하고 측정하기 
#VIF (Variance Inflation Factor)
: 피처 간의 다중 공선성을 측정하는 지표, 특정 피처가 다른 피처들로 얼마나 잘 설명될 수 있는지를 나타냄. 
```python 
# Import required libraries
from statsmodels.stats.outliers_influence import variance_inflation_factor

features_org = train.columns[1:-1]
train_x = train[features_org]

vif = pd.DataFrame()
vif["features"] = train_x.columns

# 빈 리스트를 생성합니다.
VIF_list = []

# 각 피처에 대해 반복합니다.
for i in range(len(train_x.columns)):

    # variance_inflation_factor 함수를 사용하여 해당 피처의 VIF 값을 계산합니다.
    VIF_value = variance_inflation_factor(train_x.values, i)

    # 계산된 VIF 값을 리스트에 추가합니다.
    VIF_list.append(VIF_value)

# VIF 값 리스트를 DataFrame에 추가합니다.
vif["VIF"] = VIF_list

display(vif)

# Set the figure size
plt.figure(figsize=(10, 4))

# Create a bar plot of VIF values
sns.barplot(x="VIF", y="features", data=vif.sort_values("VIF", ascending=False))

# Show the plot
plt.show() 
```
![](Pasted%20image%2020250312170437.png)

# 10. RandomForest에 의한 feature 중요도 확인 
```python 
from sklearn.ensemble import RandomForestClassifier

features = train.columns[:-1]
train_x = train.iloc[:, 1:-1]
train_y = train.iloc[:,-1]

RF_model = RandomForestClassifier(random_state = 42)
RF_model.fit(train_x,train_y)
importances = RF_model.feature_importances_ 
feature_names = RF_model.feature_names_in_ 

plt.figure(figsize=(12,4))
sns.barplot(x=feature_names, y= importances)
plt.show()
```
![](Pasted%20image%2020250312171333.png)

# 11. Logistic Regression에 이한 feature 중요도 확인 

- 데이터 표준화 : StandardScalar를 사용하여 feature들을 표준화한다. 이렇게하면 feature가 동일한 스케일을 갖게 되어, 모델의 훈련 성능이 향상 된다. 
- 표준화란? 평균을 0, 표준편차를 1로 조정하는 과정
```python 
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

features = list(train.columns[1:-1])
train_x = train[features]
train_y = train['Outcome']

scaler = StandardScaler()
train_scaled_x = train_x.copy()
train_scaled_x[features] = scaler.fit_transform(train_x)

LR_model = LogisticRegression(random_state = 42, max_iter=2000)
LR_model.fit(train_scaled_x,train_y)
importances = list(np.abs(LR_model.coef_[0]))
feature_names = features

display(importances)
display(feature_names)
plt.figure(figsize=(12,4))
sns.barplot(x=feature_names, y= importances)

plt.show()
```
![](Pasted%20image%2020250312172154.png)

# 12. 기본 교차 검증 성능 
: 랜더 포레스트 분류기를 사용하여 교차 검증(cross-validation)을 수행하고, 다양한 평가 지표를 기반으로 모델의 성능을 평가한다. 
+) 교차 검증 : 훈련 데이터와 테스트 데이터를 나누는 방법. 
+) K-Fold를 사용한 교차 검증 : 데이터를 여러 개의 폴드(fold)로 나누고, 각 폴드가 한번씩 테스트셋이 되도록 반복 -> 모든 데이터를 학습에 활용 가능
+) 4-Fold 교차 검증 -> 훈련 데이터를 4개 폴드로 나눈다. ![](Pasted%20image%2020250312175130.png)
: StratifiedKFold를 사용하여 훈련 데이터를 4개의 폴드로 나누고, 각 폴드에서의 정확도, 정밀도, 재현율, F1 점수를 계산한다. 
```python 
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold

features_org = train.columns[1:-1]

train_x = train.iloc[:, 1:-1]
train_y = train['Outcome']

kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
'''
StratifiedKFold 
: 타겟 변수에서 각 클래스(0, 1)의 비율을 유지하면서 데이터를 4개 폴드(fold)로 나눔(원본 데이터와 동일하게 유지됨) 
'''

# 계층적 K-Fold 교차 검증 사용
display("#######  기본 교차 검증 성능  #########")

RF_model = RandomForestClassifier(random_state = 42)
cv_result = cross_validate(RF_model, train_x, train_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
'''
cross_validate
: 교차 검증을 수행하여 머신러닝 모델의 성능을 평가하는 함수. 
: K-Fold, StratifiedKFold와 함께 사용되어, 데이터를 여러 개의 폴드로 나누고, 모델을 반복적으로 학습 및 평가하여 성능을 측정한다. 
:train_test_split()와 달리 데이터를 여러번 학습하고 평가하여 평균 성능을 측정한다. 
: 단순히 정확도(acc)만 계산하는 cross_val_score()와 달리, 정밀도(precision), 재현율(recall), F1-score 등 다양한 평가 지표를 한번에 반환할 수 있다. 
: 훈련시간(fit_time), 테스트 시간(score_time) 정보 제공


'''
df_cv_result = pd.DataFrame(cv_result, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(df_cv_result)
display(df_cv_result.describe().loc['mean',:].round(4).T)
```


# 13. IQR 기반 이상치(Outlier) 검출 

```python 
# 이상치를 탐지하는 함수 정의
def detect_outliers(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1

    # IQR 기반으로 이상치 범위를 정의
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # 이상치의 인덱스를 반환
    return dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)].index

# 숫자형 데이터만 대상으로 이상치 탐지
numeric_columns = train.select_dtypes(include=[np.number]).columns.tolist()

outliers_dict = {}
for column in numeric_columns:
    outliers = detect_outliers(train, column)
    if len(outliers) > 0:
        outliers_dict[column] = outliers
    display(f"num of outlier of {column} : {len(outliers)}")

display(outliers_dict)
# outliers_dict: dict => column : 이상 있는 인덱스 

```
![](Pasted%20image%2020250319171321.png)
# 14. IQR 기반의 이상치(Outlier) 중위값 대체 및 교차 검증 변화 확인

```python 
train_dout_median = train.copy()

#이상치를 중앙값으로 대체
for column, outlier_indices in outliers_dict.items():
'''
outliers_dict[컬럼명] = 이상치 인덱스 리스트 
: 이상치 인덱스를 저장할 딕셔너리 
'''
    median_value = train_dout_median[column].median()
    train_dout_median.loc[outlier_indices, column] = median_value
'''
train.loc[행의 이름, 열의 이름] : 특정 행과 열을 선택하는 pandas 인덱싱 방식
'''
train_dout_median_x = train_dout_median[features_org]
train_dout_median_y = train_dout_median['Outcome']

RF_model = RandomForestClassifier(random_state = 42)

# 이상치 처리 후 RandomForest를 사용한 교차 검증 성능 확인
cv_result_dout_median = cross_validate(RF_model, train_dout_median_x, train_dout_median_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
df_cv_result_dout_median = pd.DataFrame(cv_result_dout_median, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(df_cv_result_dout_median)
display(df_cv_result_dout_median.describe().loc['mean',:].to_frame().T)
```
![](Pasted%20image%2020250319171330.png)
# 15. IQR 기반의 이상치(Outlier) 제거 및 교차 검증 성능 변화 확인
: 이상치를 완전히 제거 

```python 
train_delete_outlier = train.copy()

# 원본 train 데이터에서 이상치 제거
rows_to_drop = set()

for column in features_org:
    outliers_indices = detect_outliers(train_delete_outlier, column)
    rows_to_drop.update(outliers_indices)

train_delete_outlier = train_delete_outlier.drop(rows_to_drop)

train_delete_outlier_x = train_delete_outlier[features_org]
train_delete_outlier_y = train_delete_outlier['Outcome']

# 이상치를 제거한 후 RandomForest를 사용한 교차 검증 성능 확인
cv_result_delete_outlier = cross_validate(RF_model, train_delete_outlier_x, train_delete_outlier_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
df_cv_result_delete_outlier = pd.DataFrame(cv_result_delete_outlier, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(f"IQR 기반의 이상치 제거한 갯수 : {len(train) - len(train_delete_outlier)} 개,  비율 : {(len(train) - len(train_delete_outlier))/len(train) * 100.0}")

display(df_cv_result_delete_outlier)
display(df_cv_result_delete_outlier.describe().loc['mean',:].to_frame().T)
```
![](Pasted%20image%2020250319171402.png)

# 16. Z-score 기반의 이상치 제거 및 교차 검증 성능 변화 확인 

```python
from scipy import stats

# Z-score 기반 이상치 제거
z_scores = np.abs(stats.zscore(train_x))

threshold = 3  # 이 값을 조절하여 이상치로 간주되는 임계점을 설정합니다.
train_zscore = train.copy()[(z_scores < threshold).all(axis=1)]

display(f"z_score 기반의 이상치 제거한 갯수 : {len(train) - len(train_zscore)} 개, 비율 : {(len(train) - len(train_zscore))/len(train) * 100.0}")

# 데이터 업데이트
train_zscore_x = train_zscore[features_org]
train_zscore_y = train_zscore['Outcome']

display("####### Z-score 기반 이상치 제거 후 교차 검증 성능 #########")

RF_model = RandomForestClassifier(random_state=42)
cv_result_zscore = cross_validate(RF_model, train_zscore_x, train_zscore_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
df_cv_result_zscore = pd.DataFrame(cv_result_zscore, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])


display(df_cv_result_zscore)
display(df_cv_result_zscore.describe().loc['mean',:].to_frame().T)
```

![](Pasted%20image%2020250319172625.png)

# 17. SMOTE 통한 데이터 불균형 
오버 샘플링을 통해 소수 클래스의 데이터를 증가시켜보고, 그 결과로 얼마나 정확도 성능이 높아지는 지 검증. 
SMOTE의 KMeansSMOTE 방법을 사용하여 오버샘플링을 적용하고, RandomForest 모델을 사용해 성능을 평가. 

```python 
from imblearn.over_sampling import SMOTE, BorderlineSMOTE,KMeansSMOTE,SVMSMOTE
from sklearn.metrics import accuracy_score

rf_model_resampled_ = RandomForestClassifier(random_state = 42)

# 교차 검증을 수동으로 구현하기 위한 리스트 초기화
accuracies = []

kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
smote_kmeans = KMeansSMOTE(random_state=42)

for train_idx, val_idx in kf.split(train_zscore_x, train_zscore_y):

    # 학습 데이터와 검증 데이터 분할
    X_train, X_val = train_zscore_x.iloc[train_idx], train_zscore_x.iloc[val_idx]
    y_train, y_val = train_zscore_y.iloc[train_idx], train_zscore_y.iloc[val_idx]

    # 학습 데이터에만 SMOTE 오버샘플링 적용
    X_train_resampled, y_train_resampled = smote_kmeans.fit_resample(X_train, y_train)

    # 오버샘플링된 학습 데이터로 모델 학습
    rf_model_resampled_.fit(X_train_resampled, y_train_resampled)

    # 검증 데이터에 대한 예측
    val_predictions = rf_model_resampled_.predict(X_val)

    # 성능 지표 계산
    accuracies.append(accuracy_score(y_val, val_predictions))


# 성능 지표의 평균 계산
mean_accuracy = np.mean(accuracies)


display(f"accuracy of each Fold : {accuracies}")
display(f"accuracy of mean_accuracy : {mean_accuracy}")
```
**'accuracy of each Fold : [0.821917808219178, 0.7534246575342466, 0.7602739726027398, 0.8]'**

**'accuracy of mean_accuracy : 0.7839041095890411'**

# 18. feature pair의 조합 연산 통한 새로운 feature 생성 

특정 피처의 쌍을 선택하고, 이들의 차이, 합, 그리고 비율을 계산하여 새로운 피처를 생성하고, 이렇게 생성된 각 피처에 대해 교차 검증을 수행하고, 이를 통해 해당 피처가 모델의 성능에 어떤 영향을 미치는지 보기. 
![](Pasted%20image%2020250319181531.png)

```python 
import itertools

# 기존 피처의 조합을 생성하고, 새로운 피처를 추가한 후 각 조합에 대한 교차 검증 점수를 계산합니다.
# 그 중에서 가장 높은 정확도를 가진 피처만 선택합니다.

# RandomForest 모델과 KFold 객체를 생성합니다.
rf_model = RandomForestClassifier(random_state = 42)

# 주어진 피처의 조합을 생성합니다.
features_subset = ['Insulin', 'Age', 'BMI']
feature_combinations = list(itertools.combinations(features_subset, 2))

cv_scores = {}
for feature_pair in feature_combinations:
    feature1, feature2 = feature_pair

    train_try = train_zscore_x.copy()

    # 새로운 피처를 추가합니다.
    train_try[f'{feature1}_{feature2}_Diff'] = train_try[feature1] - train_try[feature2]
    train_try[f'{feature1}_{feature2}_Sum'] = train_try[feature1] + train_try[feature2]
    train_try[f'{feature1}_{feature2}_Ratio'] = train_try[feature1] / (train_try[feature2].replace(0, train_try[feature2].mean()))

    features_to_evaluate = [f'{feature1}_{feature2}_Diff', f'{feature1}_{feature2}_Sum', f'{feature1}_{feature2}_Ratio']

    # 각 피처에 대한 교차 검증 점수를 계산합니다.
    feature_scores = {}
    for feature in features_to_evaluate:
        scores = cross_val_score (rf_model, pd.concat([train_zscore_x, train_try[feature]], axis=1), train_zscore_y, cv=kf, scoring='accuracy')
        feature_scores[feature] = scores.mean()

    # 가장 높은 점수를 가진 피처만 선택합니다.
    best_feature = max(feature_scores, key=feature_scores.get)
    cv_scores[best_feature] = feature_scores[best_feature]
    display(f"cv_scores[{best_feature}] : {cv_scores[best_feature]}")

# 점수를 기준으로 정렬합니다.

# 먼저, cv_scores 딕셔너리의 각 항목을 리스트로 변환합니다.
items = list(cv_scores.items())

# 그 다음, 이 리스트를 정렬합니다. 각 항목은 (key, value) 쌍이므로, item[1]을 사용하여 값을 기준으로 정렬합니다.
sorted_items = sorted(items, key=lambda item: item[1], reverse=True)

# 이제 이 정렬된 리스트를 다시 딕셔너리로 변환합니다.
cv_scores = dict(sorted_items)

display(cv_scores)
```

**'cv_scores[Insulin_Age_Sum] : 0.7839631554085971'**

**'cv_scores[Insulin_BMI_Ratio] : 0.7822626358053849'**

****'cv_scores[Age_BMI_Ratio] : 0.7668162494095419'****

****{'Insulin_Age_Sum': 0.7839631554085971,****
 ****'Insulin_BMI_Ratio': 0.7822626358053849,****
 ****'Age_BMI_Ratio': 0.7668162494095419}****

# 19. feature pair의 조합 연산 통한 feature 추가하여 교차 검증 성능 확인 

위에서 유용하다고 판단한 두 개의 피처, insulin_age_sum, insulin_BMI_Ratio를 train_zscore에 추가하고, 교차 검증 성능을 확인해보기. 

```python 
from sklearn.ensemble import RandomForestClassifier

# 피쳐 생성
train_try = train_zscore.copy()

train_try['Insulin_Age_Sum'] = train_try['Insulin'] + train_try['Age']
train_try['BMI'] = train_try['BMI'].replace(0, train_try['BMI'].mean())
train_try['Insulin_BMI_Ratio'] = train_try['Insulin_Age_Sum'] / train_try['BMI']

# 피쳐 추가
train_prep = train_zscore.copy()
train_prep['Insulin_Age_Sum'] = train_try['Insulin_Age_Sum']
train_prep['Insulin_BMI_Ratio'] = train_try['Insulin_BMI_Ratio']

train_prep_y= train_prep['Outcome']
train_prep_x = train_prep.drop(['ID', 'Outcome'], axis=1)

RF_model_prep = RandomForestClassifier(random_state=42)
cv_result_prep = cross_validate(RF_model_prep, train_prep_x, train_zscore_y, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])
df_cv_result_prep = pd.DataFrame(cv_result_prep, columns=['test_accuracy', 'test_precision', 'test_recall', 'test_f1'])

display(df_cv_result_prep)
display(df_cv_result_prep.describe().loc['mean',:].to_frame().T)

display(train_prep_x.head(5))
```
![](Pasted%20image%2020250319182908.png)

# 20. test 데이터에 동일한 피처 생성, 추가하기 
train_zscore에 생성하였던 두개의 피쳐 'Insulin_Age_Sum', 'Insulin_BMI_Ratio'를 test 데이터에 추가하고, 추론 결과를 csv에 저장하여 제출하도록 합시다.
```python 
test['Insulin_Age_Sum'] = test['Insulin'] + test['Age']
test['BMI'] = test['BMI'].replace(0, test['BMI'].mean())
test['Insulin_BMI_Ratio'] = test['Insulin_Age_Sum'] / test['BMI']

test.head(5)
```

# 21. 모델 학습, 추론하여 제출 파일 생성하기 

-----
# [step 5] 
